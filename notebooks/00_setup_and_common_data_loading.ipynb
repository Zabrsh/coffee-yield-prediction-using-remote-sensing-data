{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52565cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# notebooks/00_setup_and_common_data_loading.ipynb\n",
    "# ==============================================================================\n",
    "\n",
    "# # 00 - Setup and Common Data Loading\n",
    "# This notebook performs essential setup steps and loads common data used across the project.\n",
    "# It covers:\n",
    "# 1.  Initializing Google Earth Engine (GEE).\n",
    "# 2.  Authenticating with Google Cloud services (GEE, GCS).\n",
    "# 3.  Defining global project parameters (e.g., GEE project, GCS bucket, date ranges).\n",
    "# 4.  Loading and preprocessing administrative boundary data (woredas).\n",
    "# 5.  Setting up necessary directory structures.\n",
    "\n",
    "# ## 1. Initialize Google Earth Engine and Authenticate\n",
    "# Authenticate and initialize the Earth Engine API and Google Cloud Colab authentication.\n",
    "\n",
    "import ee\n",
    "from google.colab import auth\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Authenticate Google Colab for GEE and GCS access\n",
    "print(\"Authenticating Google Colab...\")\n",
    "auth.authenticate_user()\n",
    "print(\"Authentication complete.\")\n",
    "\n",
    "# Initialize Earth Engine\n",
    "print(\"Initializing Earth Engine...\")\n",
    "try:\n",
    "    # Replace 'your-gee-project-id' with your actual GEE project ID\n",
    "    ee.Initialize(project='bensa-coffee-yield')\n",
    "    print(\"Earth Engine initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Earth Engine: {e}\")\n",
    "    print(\"Please ensure you have authenticated and your GEE project ID is correct.\")\n",
    "\n",
    "# ## 2. Define Project Parameters\n",
    "# Define important variables such as the GCS bucket name, date ranges for data export, and paths.\n",
    "\n",
    "# --- GCS Configuration ---\n",
    "# IMPORTANT: Replace 'your-gcs-bucket-name' with the name of your GCS bucket\n",
    "BUCKET_NAME = 'bensa-coffee-yield' # <<< REPLACE THIS WITH YOUR GCS BUCKET NAME\n",
    "print(f\"Using GCS Bucket: {BUCKET_NAME}\")\n",
    "\n",
    "# --- Date Ranges for Data Export ---\n",
    "# Define the period for which to export satellite and climate data.\n",
    "# This should ideally cover all historical yield data years + future prediction year (e.g., 2025).\n",
    "START_YEAR = 2017\n",
    "END_YEAR = 2025 # Inclusive, so data up to Dec 31, 2025\n",
    "# GEE export dates are typically 'YYYY-MM-DD'\n",
    "START_DATE = f'{START_YEAR}-01-01'\n",
    "END_DATE = f'{END_YEAR}-12-31' # For the last year, include all months\n",
    "\n",
    "print(f\"Data export period: {START_DATE} to {END_DATE}\")\n",
    "\n",
    "# --- Directory Paths ---\n",
    "# Define paths for raw, processed, and GEE export data\n",
    "data_dir = '../data/'\n",
    "input_data_dir = os.path.join(data_dir, 'input/')\n",
    "processed_data_dir = os.path.join(data_dir, 'processed/')\n",
    "gee_exports_dir = os.path.join(data_dir, 'gee_exports/')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(input_data_dir, exist_ok=True)\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "os.makedirs(gee_exports_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(processed_data_dir, 'coffee_extents'), exist_ok=True)\n",
    "os.makedirs(os.path.join(gee_exports_dir, 'sentinel2'), exist_ok=True)\n",
    "os.makedirs(os.path.join(gee_exports_dir, 'era5'), exist_ok=True)\n",
    "os.makedirs(os.path.join(gee_exports_dir, 'srtm'), exist_ok=True)\n",
    "os.makedirs(os.path.join(gee_exports_dir, 'smap'), exist_ok=True)\n",
    "\n",
    "print(\"\\nProject directories created/checked.\")\n",
    "\n",
    "# ## 3. Load and Preprocess Administrative Boundaries\n",
    "# Load the Sidama woreda (district) boundaries. This GeoDataFrame will be used throughout the project\n",
    "# for filtering, clipping, and aggregation.\n",
    "\n",
    "# Path to your administrative boundary shapefile (assuming it's in data/input)\n",
    "# Make sure to place your shapefile (e.g., sidama_woredas.shp) and its accompanying\n",
    "# files (.dbf, .shx, .prj, .cpg) in the `data/input/` directory.\n",
    "WOREDAS_SHAPEFILE_PATH = os.path.join(input_data_dir, 'sidama_woredas.shp') # <<< MAKE SURE THIS FILE EXISTS\n",
    "\n",
    "# Output path for the processed GeoJSON\n",
    "PROCESSED_WOREDAS_GEOJSON_PATH = os.path.join(processed_data_dir, 'sidama_woredas.geojson')\n",
    "\n",
    "# Load the shapefile\n",
    "gdf_woredas = None\n",
    "try:\n",
    "    if not os.path.exists(WOREDAS_SHAPEFILE_PATH):\n",
    "        print(f\"Error: Woredas shapefile not found at {WOREDAS_SHAPEFILE_PATH}.\")\n",
    "        print(\"Please place `sidama_woredas.shp` (and its accompanying files like .dbf, .shx, .prj) in the 'data/input/' directory.\")\n",
    "    else:\n",
    "        gdf_woredas = gpd.read_file(WOREDAS_SHAPEFILE_PATH)\n",
    "        print(f\"\\nLoaded GeoDataFrame with {len(gdf_woredas)} woredas.\")\n",
    "        print(gdf_woredas.head())\n",
    "\n",
    "        # Ensure 'Woreda_ID' is string for consistent merging later\n",
    "        if 'Woreda_ID' in gdf_woredas.columns:\n",
    "            gdf_woredas['Woreda_ID'] = gdf_woredas['Woreda_ID'].astype(str)\n",
    "            print(\"Woreda_ID column converted to string type.\")\n",
    "        else:\n",
    "            print(\"Warning: 'Woreda_ID' column not found. Ensure your shapefile has a unique ID column for woredas.\")\n",
    "\n",
    "        # Optionally, simplify geometries or ensure valid geometries\n",
    "        gdf_woredas['geometry'] = gdf_woredas.geometry.buffer(0) # Fixes invalid geometries\n",
    "\n",
    "        # Save the processed GeoDataFrame as a GeoJSON for easier loading in subsequent notebooks\n",
    "        gdf_woredas.to_file(PROCESSED_WOREDAS_GEOJSON_PATH, driver='GeoJSON')\n",
    "        print(f\"âœ… Processed woredas saved to {PROCESSED_WOREDAS_GEOJSON_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during woreda data loading/preprocessing: {e}\")\n",
    "    gdf_woredas = None # Ensure it's None if loading fails\n",
    "\n",
    "# ## Common Variables for GEE (as ee.FeatureCollection)\n",
    "# Convert the GeoDataFrame to an Earth Engine FeatureCollection for use in GEE exports.\n",
    "\n",
    "ee_woredas = None\n",
    "if gdf_woredas is not None:\n",
    "    try:\n",
    "        # Convert GeoDataFrame to EE FeatureCollection\n",
    "        # This requires converting GeoJSON string to EE object\n",
    "        geojson_str = gdf_woredas.to_json()\n",
    "        ee_woredas = ee.FeatureCollection(geojson_str)\n",
    "        print(\"\\nGeoDataFrame converted to Earth Engine FeatureCollection.\")\n",
    "        print(f\"EE FeatureCollection size: {ee_woredas.size().getInfo()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting GeoDataFrame to EE FeatureCollection: {e}\")\n",
    "        ee_woredas = None\n",
    "else:\n",
    "    print(\"\\nSkipping EE FeatureCollection conversion as woreda data is not loaded.\")\n",
    "\n",
    "# This notebook should be run first to set up the environment and load common data.\n",
    "# The `gdf_woredas` and `ee_woredas` variables, along with `BUCKET_NAME`, `START_DATE`, `END_DATE`, etc.,\n",
    "# will be used by subsequent notebooks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
